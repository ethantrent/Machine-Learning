{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b561ad6",
   "metadata": {},
   "source": [
    "# Problem: House Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65c2d4f",
   "metadata": {},
   "source": [
    "You are tasked with predicting the price of houses based on their size (in square feet). You have data from a real estate company that includes the size of various houses and their corresponding prices.\n",
    "\n",
    "The goal is to fit a linear regression model that can predict the price of a house given its size.\n",
    "\n",
    "1. Problem Statement\n",
    "\n",
    "You are given data on the size (in square feet) and the price (in dollars) of various houses in a neighborhood. Your task is to build a linear regression model that can predict the price of a house based on its size.\n",
    "\n",
    "2. Dataset\n",
    "\n",
    "Let's assume you have the following dataset:\n",
    "\n",
    "Size (sq ft)\tPrice (dollars)\n",
    "[1500\t300,000]\n",
    "[1800\t350,000]\n",
    "[2400\t400,000]\n",
    "[3000\t500,000]\n",
    "[3500\t600,000]\n",
    "\n",
    "You will perform linear regression on this data. The goal is to learn the optimal parameters \n",
    "ùë§\n",
    "w (slope) and \n",
    "ùëè\n",
    "b (intercept) for the model that minimizes the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b505ca",
   "metadata": {},
   "source": [
    "3. Dataset Preparation\n",
    "\n",
    "The dataset is represented by two variables:\n",
    "\n",
    "ùë•\n",
    "train\n",
    "x\n",
    "train\n",
    "\t‚Äã\n",
    "\n",
    ": The sizes of the houses (in square feet).\n",
    "\n",
    "ùë¶\n",
    "train\n",
    "y\n",
    "train\n",
    "\t‚Äã\n",
    "\n",
    ": The corresponding prices (in dollars).\n",
    "\n",
    "4. Cost Function\n",
    "\n",
    "You will use the cost function to evaluate the performance of the linear regression model\n",
    "\n",
    "\n",
    "5. Gradient Descent\n",
    "\n",
    "You will use gradient descent to update the parameters \n",
    "ùë§\n",
    "w and \n",
    "ùëè\n",
    "b iteratively:\n",
    "\n",
    "\n",
    "where\n",
    "ùõº\n",
    "Œ± is the learning rate,\n",
    "ùë§\n",
    "w and \n",
    "ùëè\n",
    "b, respectively.\n",
    "\n",
    "6. Exercise\n",
    "6.1: Implement the Cost Function\n",
    "\n",
    "Write the compute_cost() function to compute the cost function \n",
    "\n",
    "6.2: Implement the Gradient Descent\n",
    "\n",
    "Write the compute_gradient() function to compute the gradients \n",
    "\n",
    "\n",
    "6.3: Perform Gradient Descent\n",
    "\n",
    "Use gradient descent to learn the optimal values of \n",
    "ùë§\n",
    "w and \n",
    "ùëè\n",
    "b using the provided dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4a2981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example Data\n",
    "x_train = np.array([1500, 1800, 2400, 3000, 3500])\n",
    "y_train = np.array([300000, 350000, 400000, 500000, 600000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebc68d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute Cost\n",
    "def compute_cost(x, y, w, b):\n",
    "    m = len(x)  # Number of training examples\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(m):\n",
    "        f_wb = w * x[i] + b           # Equation: f_{w,b}(x^{(i)}) = w * x^{(i)} + b\n",
    "        cost = (f_wb - y[i]) ** 2     # Equation: cost^{(i)} = (f_{w,b}(x^{(i)}) - y^{(i)})^2\n",
    "        total_cost += cost\n",
    "    total_cost /= (2 * m)             # Equation: J(w, b) = (1/(2m)) * sum_{i=1}^m (f_{w,b}(x^{(i)}) - y^{(i)})^2\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519b4a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute Gradient\n",
    "def compute_gradient(x, y, w, b):\n",
    "    m = len(x)\n",
    "    dj_dw = 0   # Gradient with respect to w\n",
    "    dj_db = 0   # Gradient with respect to b\n",
    "\n",
    "    for i in range(m):\n",
    "        f_wb = w * x[i] + b\n",
    "        dj_dw += (f_wb - y[i]) * x[i]  # Equation: (f_{w,b}(x^{(i)}) - y^{(i)}) * x^{(i)}\n",
    "        dj_db += f_wb - y[i]           # Equation: (f_{w,b}(x^{(i)}) - y^{(i)})\n",
    "    dj_dw /= m  # Equation: dj_dw = (1/m) * sum_{i=1}^m (f_{w,b}(x^{(i)}) - y^{(i)}) * x^{(i)}\n",
    "    dj_db /= m  # Equation: dj_db = (1/m) * sum_{i=1}^m (f_{w,b}(x^{(i)}) - y^{(i)})\n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d43d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient Descent\n",
    "def gradient_descent(x, y, w_in, b_in, alpha, num_iters):\n",
    "    m = len(x)\n",
    "    w = w_in    # Initial value for w\n",
    "    b = b_in    # Initial value for b\n",
    "    J_history = []  # record cost at each iteration\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        dj_dw, dj_db = compute_gradient(x, y, w, b)\n",
    "        w -= alpha * dj_dw     # Equation: w := w - alpha * dj_dw\n",
    "        b -= alpha * dj_db     # Equation: b := b - alpha * dj_db\n",
    "        cost = compute_cost(x, y, w, b)     # # Equation: J(w, b) = (1/(2m)) * sum_{i=1}^m (f_{w,b}(x^{(i)}) - y^{(i)})^2\n",
    "        J_history.append(cost)\n",
    "\n",
    "        if i % (num_iters // 10) == 0:\n",
    "            print(f\"Iteration {i}: Cost = {cost:.2f}\")\n",
    "    \n",
    "    return w, b, J_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
